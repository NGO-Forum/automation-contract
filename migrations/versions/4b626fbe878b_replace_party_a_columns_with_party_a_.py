"""Replace party_a columns with party_a_info JSON

Revision ID: 4b626fbe878b
Revises: 875f2c4f95cb
Create Date: 2025-09-11 15:43:08.511124

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import mysql

# revision identifiers, used by Alembic.
revision = '4b626fbe878b'
down_revision = '875f2c4f95cb'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    # Step 1: Add the new party_a_info column (nullable=True initially for migration)
    with op.batch_alter_table('contracts', schema=None) as batch_op:
        batch_op.add_column(sa.Column('party_a_info', sa.JSON(), nullable=True))

    # Step 2: Migrate data from old columns to party_a_info (MySQL JSON)
    connection = op.get_bind()
    connection.execute(sa.text("""
        UPDATE contracts 
        SET party_a_info = JSON_ARRAY(
            JSON_OBJECT(
                'name', COALESCE(party_a_name, 'Mr. SOEUNG Saroeun'),
                'position', COALESCE(party_a_position, 'Executive Director'),
                'address', COALESCE(party_a_address, '#9-11, Street 476, Sangkat Tuol Tumpoung I, Phnom Penh, Cambodia')
            )
        )
        WHERE party_a_name IS NOT NULL OR party_a_position IS NOT NULL OR party_a_address IS NOT NULL
    """))

    # Step 3: Set default for rows without data (new contracts)
    connection.execute(sa.text("""
        UPDATE contracts 
        SET party_a_info = JSON_ARRAY(
            JSON_OBJECT(
                'name', 'Mr. SOEUNG Saroeun',
                'position', 'Executive Director',
                'address', '#9-11, Street 476, Sangkat Tuol Tumpoung I, Phnom Penh, Cambodia'
            )
        )
        WHERE party_a_info IS NULL
    """))

    # Step 4: Make the column non-nullable now that all rows have data
    with op.batch_alter_table('contracts', schema=None) as batch_op:
        batch_op.alter_column('party_a_info', nullable=False)

    # Step 5: Drop the old party_a columns
    with op.batch_alter_table('contracts', schema=None) as batch_op:
        batch_op.drop_column('party_a_address')
        batch_op.drop_column('party_a_position')
        batch_op.drop_column('party_a_name')

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    # Re-add the old party_a columns
    with op.batch_alter_table('contracts', schema=None) as batch_op:
        batch_op.add_column(sa.Column('party_a_address', mysql.TEXT(), nullable=True))
        batch_op.add_column(sa.Column('party_a_position', mysql.VARCHAR(length=100), nullable=True))
        batch_op.add_column(sa.Column('party_a_name', mysql.VARCHAR(length=100), nullable=True))

    # Backfill old columns from party_a_info (use first entry in array)
    connection = op.get_bind()
    connection.execute(sa.text("""
        UPDATE contracts 
        SET party_a_name = JSON_UNQUOTE(JSON_EXTRACT(party_a_info, '$[0].name')),
            party_a_position = JSON_UNQUOTE(JSON_EXTRACT(party_a_info, '$[0].position')),
            party_a_address = JSON_UNQUOTE(JSON_EXTRACT(party_a_info, '$[0].address'))
        WHERE JSON_LENGTH(party_a_info) > 0
    """))

    # Drop the new column
    with op.batch_alter_table('contracts', schema=None) as batch_op:
        batch_op.drop_column('party_a_info')

    # Re-create indexes (in case they were affected)
    with op.batch_alter_table('contracts', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_contracts_user_id'), ['user_id'], unique=False)
        batch_op.create_index(batch_op.f('uix_contract_number_deleted_at'), ['contract_number', 'deleted_at'], unique=True)

    # ### end Alembic commands ###